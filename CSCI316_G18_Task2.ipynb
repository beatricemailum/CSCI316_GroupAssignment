{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea208112",
   "metadata": {},
   "source": [
    "# CSCI316 Group Assignment 1\n",
    "# Task 2\n",
    "# Group: G18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfaaf895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.5)\n",
      "Requirement already satisfied: seaborn in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: pyspark==3.5.1 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: jupyter in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyspark==3.5.1) (0.10.9.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: notebook in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter) (7.4.5)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from jupyter) (6.30.1)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter) (8.1.7)\n",
      "Requirement already satisfied: jupyterlab in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter) (4.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel->jupyter) (1.8.16)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel->jupyter) (9.4.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel->jupyter) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel->jupyter) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel->jupyter) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=25 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel->jupyter) (27.0.1)\n",
      "Requirement already satisfied: tornado>=6.2 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel->jupyter) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipywidgets->jupyter) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipywidgets->jupyter) (3.0.15)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-console->jupyter) (3.0.51)\n",
      "Requirement already satisfied: pygments in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-console->jupyter) (2.19.2)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter) (2.0.5)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter) (0.28.1)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter) (3.1.6)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter) (2.2.6)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter) (2.16.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter) (65.5.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter) (4.13.4)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter) (3.0.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter) (0.10.2)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter) (0.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.14.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.3.8)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (311)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.5.3)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.22.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.12.1)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (4.25.0)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.21.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter) (2.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.27.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.5.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\belei\\appdata\\roaming\\python\\python311\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: fqdn in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.1.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.22)\n",
      "Requirement already satisfied: lark>=1.2.2 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.2.2)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\belei\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.9.0.20250809)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy matplotlib seaborn pyspark==3.5.1 scikit-learn jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d7d91ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, RFormula, Bucketizer, StandardScaler, OneHotEncoder\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.stat import Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0487f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"EnhancedRentalPriceClassification\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d77cb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 3.5.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Spark Version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ffc06be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder\n",
    "         .master(\"local[*]\")\n",
    "         .config(\"spark.driver.bindAddress\",\"127.0.0.1\")\n",
    "         .config(\"spark.driver.host\",\"127.0.0.1\")\n",
    "         .getOrCreate())\n",
    "\n",
    "spark.range(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ff88bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'category', 'title', 'body', 'amenities', 'bathrooms', 'bedrooms', 'currency', 'fee', 'has_photo', 'pets_allowed', 'price', 'price_display', 'price_type', 'square_feet', 'address', 'cityname', 'state', 'latitude', 'longitude', 'source', 'time']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_spark = (spark.read\n",
    "    .option(\"header\", True)\n",
    "    .option(\"inferSchema\", True)\n",
    "    .option(\"sep\", \";\")\n",
    "    .csv(\"apartments_for_rent_classified_10K.csv\"))\n",
    "\n",
    "# normalize headers (strip spaces, lowercase, replace whitespace with _)\n",
    "clean_cols = [c.strip().lower().replace(\" \", \"_\") for c in df_spark.columns]\n",
    "df_spark = df_spark.toDF(*clean_cols)\n",
    "\n",
    "print(df_spark.columns)  # check exact names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eadee50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.withColumn(\n",
    "    \"price_num\",\n",
    "    F.regexp_replace(F.col(\"price\"), r\"[^0-9\\.-]\", \"\").cast(\"double\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db786102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|         price_num|\n",
      "+-------+------------------+\n",
      "|  count|             10000|\n",
      "|   mean|         1486.2775|\n",
      "| stddev|1076.5079675665088|\n",
      "|    min|             200.0|\n",
      "|    25%|             949.0|\n",
      "|    50%|            1270.0|\n",
      "|    75%|            1695.0|\n",
      "|    max|           52500.0|\n",
      "+-------+------------------+\n",
      "\n",
      "\n",
      "=== DATA EXPLORATION ===\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- amenities: string (nullable = true)\n",
      " |-- bathrooms: string (nullable = true)\n",
      " |-- bedrooms: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- fee: string (nullable = true)\n",
      " |-- has_photo: string (nullable = true)\n",
      " |-- pets_allowed: string (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- price_display: string (nullable = true)\n",
      " |-- price_type: string (nullable = true)\n",
      " |-- square_feet: integer (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- cityname: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- time: integer (nullable = true)\n",
      " |-- price_num: double (nullable = true)\n",
      "\n",
      "+---+--------+-----+----+---------+---------+--------+--------+---+---------+------------+-----+-------------+----------+-----------+-------+--------+-----+--------+---------+------+----+---------+\n",
      "| id|category|title|body|amenities|bathrooms|bedrooms|currency|fee|has_photo|pets_allowed|price|price_display|price_type|square_feet|address|cityname|state|latitude|longitude|source|time|price_num|\n",
      "+---+--------+-----+----+---------+---------+--------+--------+---+---------+------------+-----+-------------+----------+-----------+-------+--------+-----+--------+---------+------+----+---------+\n",
      "|  0|       0|    0|   0|        0|        0|       0|       0|  0|        0|           0|    0|            0|         0|          0|      0|       0|    0|       0|        0|     0|   0|        0|\n",
      "+---+--------+-----+----+---------+---------+--------+--------+---+---------+------------+-----+-------------+----------+-----------+-------+--------+-----+--------+---------+------+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_spark\n",
    " .select(\"price_num\")\n",
    " .summary()\n",
    " .show())\n",
    "\n",
    "print(\"\\n=== DATA EXPLORATION ===\")\n",
    "df_spark.printSchema()\n",
    "\n",
    "#null counts\n",
    "df_spark.select([\n",
    "    F.count(F.when(F.col(c).isNull() | F.isnan(c), c)).alias(c) for c in df_spark.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9967935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Data Preparation ===\n",
      "Basic data cleaning...\n",
      "\n",
      "Creating engineered features with RFormula approach\n",
      "\n",
      "New features created successfully\n",
      "\n",
      "Creating price categories for classification\n",
      "Price boundaries: [200.0, 1000.0, 1465.0, 52500.0]\n",
      "Price category distribution:\n",
      "+--------------+-----------+-----+\n",
      "|price_category|price_label|count|\n",
      "+--------------+-----------+-----+\n",
      "|           0.0|        Low| 2999|\n",
      "|           1.0|     Medium| 3322|\n",
      "|           2.0|       High| 3679|\n",
      "+--------------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#prepare the Data for Machine Learning Algorithms\n",
    "print(\"\\n=== Data Preparation ===\")\n",
    "\n",
    "#start with clean data\n",
    "print(\"Basic data cleaning...\")\n",
    "print()\n",
    "df_clean = df_spark.filter(col('price').isNotNull() & (col('price') > 0))\n",
    "\n",
    "#convert price to double to ensure it's numeric\n",
    "df_clean = df_clean.withColumn(\"price\", col(\"price\").cast(\"double\"))\n",
    "\n",
    "#fill missing values with safe defaults\n",
    "df_clean = df_clean.fillna({\n",
    "    'bedrooms': 1.0,\n",
    "    'bathrooms': 1.0,\n",
    "    'square_feet': 500.0,\n",
    "    'latitude': 0.0,\n",
    "    'longitude': 0.0,\n",
    "    'cityname': 'Unknown',\n",
    "    'state': 'Unknown',\n",
    "    'pets_allowed': 'Unknown',\n",
    "    'has_photo': 'No',\n",
    "    'source': 'Unknown'\n",
    "})\n",
    "\n",
    "#cast numeric columns to double\n",
    "numeric_cols = ['bedrooms', 'bathrooms', 'square_feet', 'latitude', 'longitude']\n",
    "for col_name in numeric_cols:\n",
    "    if col_name in df_clean.columns:\n",
    "        df_clean = df_clean.withColumn(col_name, col(col_name).cast(\"double\"))\n",
    "\n",
    "print(\"Creating engineered features with RFormula approach\")\n",
    "print()\n",
    "\n",
    "#safe feature engineering (avoiding division by zero)\n",
    "df_clean = df_clean.withColumn(\"price_per_sqft\",\n",
    "    when(col(\"square_feet\") > 0, col(\"price\") / col(\"square_feet\")).otherwise(0.0))\n",
    "\n",
    "df_clean = df_clean.withColumn(\"total_rooms\",\n",
    "    col(\"bedrooms\") + col(\"bathrooms\"))\n",
    "\n",
    "df_clean = df_clean.withColumn(\"location_score\",\n",
    "    abs(col(\"latitude\")) + abs(col(\"longitude\")))\n",
    "\n",
    "#room density feature\n",
    "df_clean = df_clean.withColumn(\"room_density\",\n",
    "    when(col(\"square_feet\") > 0, col(\"total_rooms\") / col(\"square_feet\")).otherwise(0.0))\n",
    "\n",
    "print(\"New features created successfully\")\n",
    "print()\n",
    "\n",
    "print(\"Creating price categories for classification\")\n",
    "\n",
    "#create price categories using quantiles\n",
    "price_quantiles = df_clean.approxQuantile(\"price\", [0.0, 0.33, 0.67, 1.0], 0.05)\n",
    "print(f\"Price boundaries: {price_quantiles}\")\n",
    "\n",
    "#create bucketizer\n",
    "bucketizer = Bucketizer(\n",
    "    splits=price_quantiles,\n",
    "    inputCol=\"price\",\n",
    "    outputCol=\"price_category\"\n",
    ")\n",
    "\n",
    "df_categorized = bucketizer.transform(df_clean)\n",
    "\n",
    "#add readable labels\n",
    "df_categorized = df_categorized.withColumn(\"price_label\",\n",
    "    when(col(\"price_category\") == 0.0, \"Low\")\n",
    "    .when(col(\"price_category\") == 1.0, \"Medium\")\n",
    "    .otherwise(\"High\")\n",
    ")\n",
    "\n",
    "print(\"Price category distribution:\")\n",
    "df_categorized.groupBy(\"price_category\", \"price_label\").count().orderBy(\"price_category\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aa7fe8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String indexing for categorical variables\n",
      "String indexers created.\n",
      "Feature selection...\n",
      "Selected features: ['bedrooms', 'bathrooms', 'square_feet', 'price_per_sqft', 'total_rooms', 'location_score', 'room_density', 'state_idx', 'has_photo_idx']\n"
     ]
    }
   ],
   "source": [
    "print(\"String indexing for categorical variables\")\n",
    "\n",
    "#simple string indexing for key categorical columns\n",
    "categorical_cols = ['state', 'has_photo']\n",
    "indexers = []\n",
    "indexed_cols = []\n",
    "\n",
    "for col_name in categorical_cols:\n",
    "    if col_name in df_categorized.columns:\n",
    "        indexer = StringIndexer(\n",
    "            inputCol=col_name,\n",
    "            outputCol=f\"{col_name}_idx\",\n",
    "            handleInvalid=\"keep\"\n",
    "        )\n",
    "        indexers.append(indexer)\n",
    "        indexed_cols.append(f\"{col_name}_idx\")\n",
    "\n",
    "print(\"String indexers created.\")\n",
    "\n",
    "print(\"Feature selection...\")\n",
    "\n",
    "#select reliable features\n",
    "final_features = [\n",
    "    'bedrooms', 'bathrooms', 'square_feet',\n",
    "    'price_per_sqft', 'total_rooms', 'location_score', 'room_density'\n",
    "] + indexed_cols\n",
    "\n",
    "print(f\"Selected features: {final_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60f8033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuration\n",
    "DF_READY    = df_categorized\n",
    "FEATURES_COL = \"final_features\"\n",
    "LABEL_COL    = \"price_num\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c77527af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. Train/test split...\n",
      "Training data: 8072 rows\n",
      "Test data: 1928 rows\n",
      "Train set price distribution:\n",
      "+--------------+-----------+-----+\n",
      "|price_category|price_label|count|\n",
      "+--------------+-----------+-----+\n",
      "|           0.0|        Low| 2398|\n",
      "|           1.0|     Medium| 2683|\n",
      "|           2.0|       High| 2991|\n",
      "+--------------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"6. Train/test split...\")\n",
    "\n",
    "#split data (80-20)\n",
    "train_data, test_data = df_categorized.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Training data: {train_data.count()} rows\")\n",
    "print(f\"Test data: {test_data.count()} rows\")\n",
    "\n",
    "print(\"Train set price distribution:\")\n",
    "train_data.groupBy(\"price_category\", \"price_label\").count().orderBy(\"price_category\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04516179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_features: ['bedrooms', 'bathrooms', 'square_feet', 'price_per_sqft', 'total_rooms', 'location_score', 'room_density', 'state_idx', 'has_photo_idx']\n",
      "df_categorized columns: ['id', 'category', 'title', 'body', 'amenities', 'bathrooms', 'bedrooms', 'currency', 'fee', 'has_photo', 'pets_allowed', 'price', 'price_display', 'price_type', 'square_feet', 'address', 'cityname', 'state', 'latitude', 'longitude', 'source', 'time', 'price_num', 'price_per_sqft', 'total_rooms', 'location_score', 'room_density', 'price_category', 'price_label']\n",
      "MISSING features: ['state_idx', 'has_photo_idx']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, isnan\n",
    "\n",
    "print(\"final_features:\", final_features)\n",
    "print(\"df_categorized columns:\", df_categorized.columns)\n",
    "\n",
    "missing = [c for c in final_features if c not in df_categorized.columns]\n",
    "print(\"MISSING features:\", missing)\n",
    "\n",
    "#keep only existing features\n",
    "final_features = [c for c in final_features if c in df_categorized.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c71f493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# assuming `indexers` is your list of StringIndexers you built\n",
    "idx_pipeline = Pipeline(stages=indexers)\n",
    "df_idx = idx_pipeline.fit(df_categorized).transform(df_categorized)\n",
    "\n",
    "df_feat_src = df_idx   # <- use this as the DF to assemble from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ab26fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_feat_src = df_feat_src.withColumn(\n",
    "    \"price_per_sqft\",\n",
    "    F.when((F.col(\"square_feet\").isNull()) | (F.col(\"square_feet\") <= 0), None)\n",
    "     .otherwise(F.col(\"price\") / F.col(\"square_feet\"))\n",
    ")\n",
    "\n",
    "# (optional) convert booleans to doubles if present\n",
    "bool_cols = [c for c in [\"has_photo\", \"pets_allowed\", \"fee\"] if c in df_feat_src.columns]\n",
    "for c in bool_cols:\n",
    "    df_feat_src = df_feat_src.withColumn(c, F.col(c).cast(\"double\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8476ff",
   "metadata": {},
   "source": [
    "Impute remaining nulls in numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f4b4bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "num_feats = [c for c in final_features\n",
    "             if c in df_feat_src.columns\n",
    "             and dict(df_feat_src.dtypes)[c] in (\"double\",\"int\",\"bigint\",\"float\",\"smallint\",\"tinyint\")]\n",
    "\n",
    "imputer = Imputer(strategy=\"median\", inputCols=num_feats, outputCols=num_feats)\n",
    "df_feat_src = imputer.fit(df_feat_src).transform(df_feat_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd34dc3e",
   "metadata": {},
   "source": [
    "Assembling and resplitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fdcae4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- price_num: double (nullable = true)\n",
      "\n",
      "Train rows: 8072  Test rows: 1928\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=final_features, outputCol=\"features\")\n",
    "df_ready = assembler.transform(df_feat_src)\n",
    "\n",
    "label_col = \"price_num\" if \"price_num\" in df_ready.columns else \"price\"\n",
    "\n",
    "train_data, test_data = df_ready.select(\"features\", label_col).randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "train_data.printSchema()\n",
    "print(\"Train rows:\", train_data.count(), \" Test rows:\", test_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850695dc",
   "metadata": {},
   "source": [
    "Imports before creating Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9990956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, Imputer, VectorAssembler, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e6b63e",
   "metadata": {},
   "source": [
    "## Pipelines creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31cd3d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_spark_pipeline(\n",
    "    model_type: str,\n",
    "    num_cols: list,\n",
    "    cat_cols: list,\n",
    "    label_col: str = \"price_num\",\n",
    "    use_scaler_for_lr: bool = True,\n",
    "    rf_params: dict = None,\n",
    "    gbt_params: dict = None,\n",
    "    lr_params: dict = None,\n",
    "):\n",
    "    stages = []\n",
    "\n",
    "    #impute numeric columns\n",
    "    if num_cols:\n",
    "        imputer = Imputer(strategy=\"median\", inputCols=num_cols, outputCols=num_cols)\n",
    "        stages.append(imputer)\n",
    "\n",
    "    #index and OneHot categorical columns\n",
    "    indexers = []\n",
    "    idx_names = []\n",
    "    for c in cat_cols:\n",
    "        idx = StringIndexer(inputCol=c, outputCol=f\"{c}_idx\", handleInvalid=\"keep\")\n",
    "        indexers.append(idx)\n",
    "        idx_names.append(f\"{c}_idx\")\n",
    "    if indexers:\n",
    "        stages += indexers\n",
    "        encoder = OneHotEncoder(\n",
    "            inputCols=idx_names,\n",
    "            outputCols=[f\"{c}_oh\" for c in cat_cols],\n",
    "            handleInvalid=\"keep\"\n",
    "        )\n",
    "        stages.append(encoder)\n",
    "        cat_feat_cols = [f\"{c}_oh\" for c in cat_cols]\n",
    "    else:\n",
    "        cat_feat_cols = []\n",
    "\n",
    "    #assembling features\n",
    "    feat_cols = num_cols + cat_feat_cols\n",
    "    assembler = VectorAssembler(inputCols=feat_cols, outputCol=\"features\", handleInvalid=\"keep\")\n",
    "    stages.append(assembler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fc7aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr  = LinearRegression(featuresCol=\"features\", labelCol=LABEL_COL, predictionCol=\"prediction\")\n",
    "rf  = RandomForestRegressor(featuresCol=\"features\", labelCol=LABEL_COL, predictionCol=\"prediction\",\n",
    "                            numTrees=200, maxDepth=12, seed=42)\n",
    "gbt = GBTRegressor(featuresCol=\"features\", labelCol=LABEL_COL, predictionCol=\"prediction\",\n",
    "                   maxIter=150, maxDepth=8, stepSize=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11a49a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr  = Pipeline(stages=indexers + [imputer, assembler, LinearRegression])\n",
    "pipe_rf  = Pipeline(stages=indexers + [imputer, assembler, RandomForestRegressor])\n",
    "pipe_gbt = Pipeline(stages=indexers + [imputer, assembler, GBTRegressor])\n",
    "\n",
    "pipes = {\n",
    "    \"LinearRegression\": pipe_lr,\n",
    "    \"RandomForest\":     pipe_rf,\n",
    "    \"GBT\":              pipe_gbt,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69307bcf",
   "metadata": {},
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b680697",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot recognize a pipeline stage of type <class 'abc.ABCMeta'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m lr_model = \u001b[43mpipes\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLinearRegression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\belei\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\ml\\base.py:205\u001b[39m, in \u001b[36mEstimator.fit\u001b[39m\u001b[34m(self, dataset, params)\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy(params)._fit(dataset)\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    208\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    209\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[32m    210\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\belei\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\ml\\pipeline.py:122\u001b[39m, in \u001b[36mPipeline._fit\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m stage \u001b[38;5;129;01min\u001b[39;00m stages:\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(stage, Estimator) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stage, Transformer)):\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot recognize a pipeline stage of type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mtype\u001b[39m(stage))\n\u001b[32m    123\u001b[39m indexOfLastEstimator = -\u001b[32m1\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, stage \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(stages):\n",
      "\u001b[31mTypeError\u001b[39m: Cannot recognize a pipeline stage of type <class 'abc.ABCMeta'>."
     ]
    }
   ],
   "source": [
    "lr_model = pipes[\"LinearRegression\"].fit(train_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
