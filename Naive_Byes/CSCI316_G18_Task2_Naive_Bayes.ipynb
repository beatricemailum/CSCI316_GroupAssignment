{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ydTQwcKpIzD",
        "outputId": "16c9a686-6aef-422b-c94c-f9489d29a741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark Session initialized successfully!\n",
            "Spark Version: 3.5.1\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "=== DATA EXPLORATION ===\n",
            "Schema:\n",
            "root\n",
            " |-- id: long (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- body: string (nullable = true)\n",
            " |-- amenities: string (nullable = true)\n",
            " |-- bathrooms: double (nullable = true)\n",
            " |-- bedrooms: double (nullable = true)\n",
            " |-- currency: string (nullable = true)\n",
            " |-- fee: string (nullable = true)\n",
            " |-- has_photo: string (nullable = true)\n",
            " |-- pets_allowed: string (nullable = true)\n",
            " |-- price: long (nullable = true)\n",
            " |-- price_display: string (nullable = true)\n",
            " |-- price_type: string (nullable = true)\n",
            " |-- square_feet: long (nullable = true)\n",
            " |-- address: string (nullable = true)\n",
            " |-- cityname: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- source: string (nullable = true)\n",
            " |-- time: long (nullable = true)\n",
            "\n",
            "\n",
            "Basic statistics:\n",
            "+-------+------------------+--------------------+--------------------+--------------------+-----------+---------+--------+--------+-----+---------+------------+-----------------+-------------+----------+----------------+--------------------+--------+-----+--------+---------+-----------+-----------------+\n",
            "|summary|                id|            category|               title|                body|  amenities|bathrooms|bedrooms|currency|  fee|has_photo|pets_allowed|            price|price_display|price_type|     square_feet|             address|cityname|state|latitude|longitude|     source|             time|\n",
            "+-------+------------------+--------------------+--------------------+--------------------+-----------+---------+--------+--------+-----+---------+------------+-----------------+-------------+----------+----------------+--------------------+--------+-----+--------+---------+-----------+-----------------+\n",
            "|  count|             10000|               10000|               10000|               10000|      10000|    10000|   10000|   10000|10000|    10000|       10000|            10000|        10000|     10000|           10000|               10000|   10000|10000|   10000|    10000|      10000|            10000|\n",
            "|   mean| 5.6233956528752E9|                NULL|                NULL|                NULL|        NaN|      NaN|     NaN|    NULL| NULL|     NULL|         NaN|        1486.2775|         NULL|      NULL|        945.8105|                 NaN|     NaN|  NaN|     NaN|      NaN|       NULL|1.5748911753139E9|\n",
            "| stddev|7.02102520448438E7|                NULL|                NULL|                NULL|        NaN|      NaN|     NaN|    NULL| NULL|     NULL|         NaN|1076.507967566508|         NULL|      NULL|655.755735734156|                 NaN|     NaN|  NaN|     NaN|      NaN|       NULL|3762395.147644736|\n",
            "|    min|        5508654087|housing/rent/apar...|$1,010 / Two BR -...|! ACT NOW! 1 mon ...|         AC|      1.0|     0.0|     USD|   No|       No|        Cats|              200|       $1,000|   Monthly|             101|#4 Pahrump Valley...|Aberdeen|   AK| 21.3155|-158.0221| GoSection8|       1568743976|\n",
            "|    max|        5668662559|housing/rent/shor...|wood Apartments f...|youll find all th...|Wood Floors|      NaN|     NaN|     USD|   No|      Yes|         NaN|            52500|         $999|    Weekly|           40000|Y.A Tittle Dr And...| Zachary|   WY|     NaN|      NaN|tenantcloud|       1577362186|\n",
            "+-------+------------------+--------------------+--------------------+--------------------+-----------+---------+--------+--------+-----+---------+------------+-----------------+-------------+----------+----------------+--------------------+--------+-----+--------+---------+-----------+-----------------+\n",
            "\n",
            "\n",
            "Data types and null counts:\n",
            "+---+--------+-----+----+---------+---------+--------+--------+---+---------+------------+-----+-------------+----------+-----------+-------+--------+-----+--------+---------+------+----+\n",
            "| id|category|title|body|amenities|bathrooms|bedrooms|currency|fee|has_photo|pets_allowed|price|price_display|price_type|square_feet|address|cityname|state|latitude|longitude|source|time|\n",
            "+---+--------+-----+----+---------+---------+--------+--------+---+---------+------------+-----+-------------+----------+-----------+-------+--------+-----+--------+---------+------+----+\n",
            "|  0|       0|    0|   0|        0|        0|       0|       0|  0|        0|           0|    0|            0|         0|          0|      0|       0|    0|       0|        0|     0|   0|\n",
            "+---+--------+-----+----+---------+---------+--------+--------+---+---------+------------+-----+-------------+----------+-----------+-------+--------+-----+--------+---------+------+----+\n",
            "\n",
            "+-------+-----------------+\n",
            "|summary|            price|\n",
            "+-------+-----------------+\n",
            "|  count|            10000|\n",
            "|   mean|        1486.2775|\n",
            "| stddev|1076.507967566508|\n",
            "|    min|              200|\n",
            "|    max|            52500|\n",
            "+-------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, RFormula, Bucketizer, StandardScaler, OneHotEncoder\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.stat import Correlation\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"EnhancedRentalPriceClassification\") \\\n",
        "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
        "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
        "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Spark Version: {spark.version}\")\n",
        "\n",
        "##  Discover and Visualize the Data\n",
        "\n",
        "# Read the CSV file using pandas first to handle the data\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/My Drive/BigData_grp_assignment/apartments10.csv'\n",
        "df = pd.read_csv(path, sep=None, engine=\"python\", encoding=\"cp1252\")\n",
        "\n",
        "\n",
        "df.columns = (df.columns\n",
        "              .str.strip()\n",
        "              .str.lower()\n",
        "              .str.replace(r\"\\s+\", \"_\", regex=True))\n",
        "\n",
        "# Convert to Spark DataFrame\n",
        "df_spark = spark.createDataFrame(df)\n",
        "\n",
        "# Basic data exploration\n",
        "print(\"\\n=== DATA EXPLORATION ===\")\n",
        "print(\"Schema:\")\n",
        "df_spark.printSchema()\n",
        "\n",
        "print(\"\\nBasic statistics:\")\n",
        "df_spark.describe().show()\n",
        "\n",
        "print(\"\\nData types and null counts:\")\n",
        "df_spark.select([count(when(col(c).isNull(), c)).alias(c) for c in df_spark.columns]).show()\n",
        "\n",
        "# Show price statistics for understanding distribution\n",
        "price_stats = df_spark.select(\"price\").describe()\n",
        "price_stats.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Prepare the Data for Machine Learning Algorithms\n",
        "print(\"\\n=== Data Preparation ===\")\n",
        "\n",
        "# Start with clean data\n",
        "print(\"Basic data cleaning...\")\n",
        "df_clean = df_spark.filter(col('price').isNotNull() & (col('price') > 0))\n",
        "\n",
        "# Convert price to double to ensure it's numeric\n",
        "df_clean = df_clean.withColumn(\"price\", col(\"price\").cast(\"double\"))\n",
        "\n",
        "# Fill missing values with safe defaults\n",
        "df_clean = df_clean.fillna({\n",
        "    'bedrooms': 1.0,\n",
        "    'bathrooms': 1.0,\n",
        "    'square_feet': 500.0,\n",
        "    'latitude': 0.0,\n",
        "    'longitude': 0.0,\n",
        "    'cityname': 'Unknown',\n",
        "    'state': 'Unknown',\n",
        "    'pets_allowed': 'Unknown',\n",
        "    'has_photo': 'No',\n",
        "    'source': 'Unknown'\n",
        "})\n",
        "\n",
        "# Cast numeric columns to double\n",
        "numeric_cols = ['bedrooms', 'bathrooms', 'square_feet', 'latitude', 'longitude']\n",
        "for col_name in numeric_cols:\n",
        "    if col_name in df_clean.columns:\n",
        "        df_clean = df_clean.withColumn(col_name, col(col_name).cast(\"double\"))\n",
        "\n",
        "\n",
        "\n",
        "print(\"Creating engineered features with RFormula approach\")\n",
        "\n",
        "# Safe feature engineering (avoiding division by zero)\n",
        "df_clean = df_clean.withColumn(\"price_per_sqft\",\n",
        "    when(col(\"square_feet\") > 0, col(\"price\") / col(\"square_feet\")).otherwise(0.0))\n",
        "\n",
        "df_clean = df_clean.withColumn(\"total_rooms\",\n",
        "    col(\"bedrooms\") + col(\"bathrooms\"))\n",
        "\n",
        "df_clean = df_clean.withColumn(\"location_score\",\n",
        "    abs(col(\"latitude\")) + abs(col(\"longitude\")))\n",
        "\n",
        "# Room density feature\n",
        "df_clean = df_clean.withColumn(\"room_density\",\n",
        "    when(col(\"square_feet\") > 0, col(\"total_rooms\") / col(\"square_feet\")).otherwise(0.0))\n",
        "\n",
        "print(\"New features created successfully\")\n",
        "\n",
        "print(\"Creating price categories for classification\")\n",
        "\n",
        "# Create price categories using quantiles\n",
        "price_quantiles = df_clean.approxQuantile(\"price\", [0.0, 0.33, 0.67, 1.0], 0.05)\n",
        "print(f\"Price boundaries: {price_quantiles}\")\n",
        "\n",
        "# Create bucketizer\n",
        "bucketizer = Bucketizer(\n",
        "    splits=price_quantiles,\n",
        "    inputCol=\"price\",\n",
        "    outputCol=\"price_category\"\n",
        ")\n",
        "\n",
        "df_categorized = bucketizer.transform(df_clean)\n",
        "\n",
        "# Add readable labels\n",
        "df_categorized = df_categorized.withColumn(\"price_label\",\n",
        "    when(col(\"price_category\") == 0.0, \"Low\")\n",
        "    .when(col(\"price_category\") == 1.0, \"Medium\")\n",
        "    .otherwise(\"High\")\n",
        ")\n",
        "\n",
        "print(\"Price category distribution:\")\n",
        "df_categorized.groupBy(\"price_category\", \"price_label\").count().orderBy(\"price_category\").show()\n",
        "\n",
        "print(\"String indexing for categorical variables\")\n",
        "\n",
        "# Simple string indexing for key categorical columns\n",
        "categorical_cols = ['state', 'has_photo']\n",
        "indexers = []\n",
        "indexed_cols = []\n",
        "\n",
        "for col_name in categorical_cols:\n",
        "    if col_name in df_categorized.columns:\n",
        "        indexer = StringIndexer(\n",
        "            inputCol=col_name,\n",
        "            outputCol=f\"{col_name}_idx\",\n",
        "            handleInvalid=\"keep\"\n",
        "        )\n",
        "        indexers.append(indexer)\n",
        "        indexed_cols.append(f\"{col_name}_idx\")\n",
        "\n",
        "print(\"String indexers created.\")\n",
        "\n",
        "print(\"Feature selection...\")\n",
        "\n",
        "# Select reliable features\n",
        "final_features = [\n",
        "    'bedrooms', 'bathrooms', 'square_feet',\n",
        "    'price_per_sqft', 'total_rooms', 'location_score', 'room_density'\n",
        "] + indexed_cols\n",
        "\n",
        "print(f\"Selected features: {final_features}\")\n",
        "\n",
        "print(\"6. Train/test split...\")\n",
        "\n",
        "# Split data (80-20)\n",
        "train_data, test_data = df_categorized.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "print(f\"Training data: {train_data.count()} rows\")\n",
        "print(f\"Test data: {test_data.count()} rows\")\n",
        "\n",
        "print(\"Train set price distribution:\")\n",
        "train_data.groupBy(\"price_category\", \"price_label\").count().orderBy(\"price_category\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17l2JKALsKl6",
        "outputId": "cbfc78ea-827c-4da3-9b39-7612ec565a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== BULLETPROOF DATA PREPARATION ===\n",
            "1. Basic data cleaning...\n",
            "Missing values handled and types converted.\n",
            "2. Creating engineered features with RFormula approach...\n",
            "New features created successfully.\n",
            "3. Creating price categories for classification...\n",
            "Price boundaries: [200.0, 1009.0, 1489.0, 52500.0]\n",
            "Price category distribution:\n",
            "+--------------+-----------+-----+\n",
            "|price_category|price_label|count|\n",
            "+--------------+-----------+-----+\n",
            "|           0.0|        Low| 3094|\n",
            "|           1.0|     Medium| 3335|\n",
            "|           2.0|       High| 3571|\n",
            "+--------------+-----------+-----+\n",
            "\n",
            "4. String indexing for categorical variables...\n",
            "String indexers created.\n",
            "5. Feature selection...\n",
            "Selected features: ['bedrooms', 'bathrooms', 'square_feet', 'price_per_sqft', 'total_rooms', 'location_score', 'room_density', 'state_idx', 'has_photo_idx']\n",
            "6. Train/test split...\n",
            "Training data: 8053 rows\n",
            "Test data: 1947 rows\n",
            "Train set price distribution:\n",
            "+--------------+-----------+-----+\n",
            "|price_category|price_label|count|\n",
            "+--------------+-----------+-----+\n",
            "|           0.0|        Low| 2494|\n",
            "|           1.0|     Medium| 2678|\n",
            "|           2.0|       High| 2881|\n",
            "+--------------+-----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n=== NAIVE BAYES MODEL TRAINING ===\")\n",
        "\n",
        "stages = indexers + [\n",
        "    VectorAssembler(\n",
        "        inputCols=final_features,\n",
        "        outputCol=\"features\",\n",
        "        handleInvalid=\"skip\"  # Skip rows with invalid values\n",
        "    ),\n",
        "    NaiveBayes(\n",
        "        featuresCol=\"features\",\n",
        "        labelCol=\"price_category\",\n",
        "        smoothing=1.0\n",
        "    )\n",
        "]\n",
        "\n",
        "pipeline = Pipeline(stages=stages)\n",
        "\n",
        "print(\"Training Naive Bayes model...\")\n",
        "try:\n",
        "    # Train the model\n",
        "    nb_model = pipeline.fit(train_data)\n",
        "    print(\" Model trained successfully!\")\n",
        "\n",
        "    # Make predictions\n",
        "    print(\"Making predictions on test data...\")\n",
        "    nb_predictions = nb_model.transform(test_data)\n",
        "    print(\" Predictions completed!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\" Training failed with error: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(\"Checking feature columns in training data:\")\n",
        "    for col_name in final_features:\n",
        "        if col_name in train_data.columns:\n",
        "            try:\n",
        "                null_count = train_data.filter(col(col_name).isNull()).count()\n",
        "                col_type = train_data.select(col_name).dtypes[0][1]\n",
        "                print(f\"   {col_name}: {col_type}, {null_count} nulls\")\n",
        "            except Exception as col_error:\n",
        "                print(f\"   {col_name}: Error - {col_error}\")\n",
        "        else:\n",
        "            print(f\"   {col_name}: MISSING COLUMN\")\n",
        "\n",
        "    print(\"Sample of training data:\")\n",
        "    train_data.select(final_features[:5] + [\"price_category\"]).show(5, truncate=False)\n",
        "\n",
        "    # Try with minimal features if full feature set fails\n",
        "    print(\"Trying with minimal feature set...\")\n",
        "    minimal_features = ['bedrooms', 'bathrooms']\n",
        "\n",
        "    minimal_pipeline = Pipeline(stages=[\n",
        "        VectorAssembler(\n",
        "            inputCols=minimal_features,\n",
        "            outputCol=\"features\",\n",
        "            handleInvalid=\"skip\"\n",
        "        ),\n",
        "        NaiveBayes(\n",
        "            featuresCol=\"features\",\n",
        "            labelCol=\"price_category\",\n",
        "            smoothing=1.0\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    try:\n",
        "        nb_model = minimal_pipeline.fit(train_data)\n",
        "        nb_predictions = nb_model.transform(test_data)\n",
        "        print(\" SUCCESS with minimal features!\")\n",
        "        final_features = minimal_features  # Update for evaluation\n",
        "    except Exception as e2:\n",
        "        print(f\" Even minimal features failed: {e2}\")\n",
        "        raise\n",
        "\n",
        "## Step 4: Fine-tune the Model (UPDATED SECTION)\n",
        "\n",
        "print(\"\\n=== MODEL FINE-TUNING ===\")\n",
        "\n",
        "# Create tuning pipeline\n",
        "nb_tuning = NaiveBayes(featuresCol=\"features\", labelCol=\"price_category\")\n",
        "tuning_stages = indexers + [\n",
        "    VectorAssembler(\n",
        "        inputCols=final_features,\n",
        "        outputCol=\"features\",\n",
        "        handleInvalid=\"skip\"\n",
        "    ),\n",
        "    nb_tuning\n",
        "]\n",
        "tuning_pipeline = Pipeline(stages=tuning_stages)\n",
        "\n",
        "# Parameter grid for smoothing\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(nb_tuning.smoothing, [0.1, 0.5, 1.0, 2.0, 5.0]) \\\n",
        "    .build()\n",
        "\n",
        "# Cross validator\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"price_category\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"accuracy\"\n",
        ")\n",
        "\n",
        "crossval = CrossValidator(\n",
        "    estimator=tuning_pipeline,\n",
        "    estimatorParamMaps=paramGrid,\n",
        "    evaluator=evaluator,\n",
        "    numFolds=3\n",
        ")\n",
        "\n",
        "print(\"Fine-tuning model with cross-validation...\")\n",
        "try:\n",
        "    nb_tuned_model = crossval.fit(train_data)\n",
        "    nb_tuned_predictions = nb_tuned_model.transform(test_data)\n",
        "\n",
        "    best_smoothing = nb_tuned_model.bestModel.stages[-1].getSmoothing()\n",
        "    print(f\"Fine-tuning completed! Best smoothing: {best_smoothing}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Fine-tuning failed: {e}\")\n",
        "    print(\"Using original model for evaluation...\")\n",
        "    nb_tuned_predictions = nb_predictions\n",
        "    best_smoothing = 1.0\n",
        "\n",
        "## Step 5: Evaluate the Model\n",
        "\n",
        "print(\"\\n=== MODEL EVALUATION ===\")\n",
        "\n",
        "# Create evaluators\n",
        "accuracy_evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"price_category\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "precision_evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"price_category\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
        "recall_evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"price_category\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
        "f1_evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"price_category\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "\n",
        "# Evaluate models\n",
        "print(\"Evaluating model performance...\")\n",
        "\n",
        "# Original model\n",
        "nb_accuracy = accuracy_evaluator.evaluate(nb_predictions)\n",
        "nb_precision = precision_evaluator.evaluate(nb_predictions)\n",
        "nb_recall = recall_evaluator.evaluate(nb_predictions)\n",
        "nb_f1 = f1_evaluator.evaluate(nb_predictions)\n",
        "\n",
        "# Tuned model\n",
        "nb_tuned_accuracy = accuracy_evaluator.evaluate(nb_tuned_predictions)\n",
        "nb_tuned_precision = precision_evaluator.evaluate(nb_tuned_predictions)\n",
        "nb_tuned_recall = recall_evaluator.evaluate(nb_tuned_predictions)\n",
        "nb_tuned_f1 = f1_evaluator.evaluate(nb_tuned_predictions)\n",
        "\n",
        "# Display results\n",
        "print(\"\\n=== MODEL PERFORMANCE COMPARISON ===\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"{'Model':<15} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"{'Original NB':<15} {nb_accuracy:<12.4f} {nb_precision:<12.4f} {nb_recall:<12.4f} {nb_f1:<12.4f}\")\n",
        "print(f\"{'Tuned NB':<15} {nb_tuned_accuracy:<12.4f} {nb_tuned_precision:<12.4f} {nb_tuned_recall:<12.4f} {nb_tuned_f1:<12.4f}\")\n",
        "\n",
        "# Determine best model\n",
        "if nb_tuned_accuracy > nb_accuracy:\n",
        "    best_model_name = \"Tuned Naive Bayes\"\n",
        "    best_predictions = nb_tuned_predictions\n",
        "    best_accuracy = nb_tuned_accuracy\n",
        "else:\n",
        "    best_model_name = \"Original Naive Bayes\"\n",
        "    best_predictions = nb_predictions\n",
        "    best_accuracy = nb_accuracy\n",
        "\n",
        "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
        "print(f\"üéØ Best Accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kn4L26cnULh",
        "outputId": "b046952c-fd6b-4551-dd3f-30e00e944761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== NAIVE BAYES MODEL TRAINING ===\n",
            "Building pipeline...\n",
            "Training Naive Bayes model...\n",
            "‚úÖ Model trained successfully!\n",
            "Making predictions on test data...\n",
            "‚úÖ Predictions completed!\n",
            "\n",
            "=== MODEL FINE-TUNING ===\n",
            "Fine-tuning model with cross-validation...\n",
            "‚úÖ Fine-tuning completed! Best smoothing: 5.0\n",
            "\n",
            "=== MODEL EVALUATION ===\n",
            "Evaluating model performance...\n",
            "\n",
            "=== MODEL PERFORMANCE COMPARISON ===\n",
            "--------------------------------------------------------------------------------\n",
            "Model           Accuracy     Precision    Recall       F1-Score    \n",
            "--------------------------------------------------------------------------------\n",
            "Original NB     0.4848       0.4837       0.4848       0.4770      \n",
            "Tuned NB        0.4848       0.4837       0.4848       0.4770      \n",
            "\n",
            "üèÜ Best Model: Original Naive Bayes\n",
            "üéØ Best Accuracy: 0.4848 (48.48%)\n"
          ]
        }
      ]
    }
  ]
}