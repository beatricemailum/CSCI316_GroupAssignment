{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff8a6665",
   "metadata": {},
   "source": [
    "# Task 2 - Apartment Rent Prediction using Decision Tree Regressor  \n",
    "\n",
    "**Objective:** Predict rental prices using Spark MLlib Decision Tree Regressor.  \n",
    "\n",
    "This notebook follows the same preprocessing as the Naive Bayes classification notebook,  \n",
    "but replaces classification with a **Decision Tree Regressor** for continuous price prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb05016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RentalPriceDecisionTree\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark Version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e22fa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Discover and Visualize the Data\n",
    "\n",
    "# Load CSV with pandas then convert to Spark DataFrame\n",
    "path = \"apartments_for_rent_classified_100K.csv\"\n",
    "df = pd.read_csv(path, sep=\";\", engine=\"python\", encoding=\"cp1252\")\n",
    "\n",
    "df.columns = (df.columns\n",
    "              .str.strip()\n",
    "              .str.lower()\n",
    "              .str.replace(r\"\\s+\", \"_\", regex=True))\n",
    "\n",
    "df_spark = spark.createDataFrame(df)\n",
    "\n",
    "print(\"\\n=== DATA EXPLORATION ===\")\n",
    "print(\"Schema:\")\n",
    "df_spark.printSchema()\n",
    "\n",
    "print(\"\\nBasic statistics:\")\n",
    "df_spark.describe().show()\n",
    "\n",
    "print(\"\\nData types and null counts:\")\n",
    "df_spark.select([count(when(col(c).isNull(), c)).alias(c) for c in df_spark.columns]).show()\n",
    "\n",
    "# Price statistics\n",
    "df_spark.select(\"price\").describe().show()\n",
    "\n",
    "## Prepare the Data for Machine Learning Algorithms\n",
    "print(\"\\n=== Data Preparation ===\")\n",
    "\n",
    "# Filter and clean\n",
    "df_clean = df_spark.filter(col('price').isNotNull() & (col('price') > 0))\n",
    "df_clean = df_clean.withColumn(\"price\", col(\"price\").cast(\"double\"))\n",
    "\n",
    "# Fill missing values\n",
    "df_clean = df_clean.fillna({\n",
    "    'bedrooms': 1.0,\n",
    "    'bathrooms': 1.0,\n",
    "    'square_feet': 500.0,\n",
    "    'latitude': 0.0,\n",
    "    'longitude': 0.0,\n",
    "    'cityname': 'Unknown',\n",
    "    'state': 'Unknown',\n",
    "    'pets_allowed': 'Unknown',\n",
    "    'has_photo': 'No',\n",
    "    'source': 'Unknown'\n",
    "})\n",
    "\n",
    "# Cast numeric columns\n",
    "numeric_cols = ['bedrooms', 'bathrooms', 'square_feet', 'latitude', 'longitude']\n",
    "for col_name in numeric_cols:\n",
    "    if col_name in df_clean.columns:\n",
    "        df_clean = df_clean.withColumn(col_name, col(col_name).cast(\"double\"))\n",
    "\n",
    "# Feature engineering\n",
    "df_clean = df_clean.withColumn(\"price_per_sqft\",\n",
    "    when(col(\"square_feet\") > 0, col(\"price\") / col(\"square_feet\")).otherwise(0.0))\n",
    "\n",
    "df_clean = df_clean.withColumn(\"total_rooms\",\n",
    "    col(\"bedrooms\") + col(\"bathrooms\"))\n",
    "\n",
    "df_clean = df_clean.withColumn(\"location_score\",\n",
    "    abs(col(\"latitude\")) + abs(col(\"longitude\")))\n",
    "\n",
    "df_clean = df_clean.withColumn(\"room_density\",\n",
    "    when(col(\"square_feet\") > 0, col(\"total_rooms\") / col(\"square_feet\")).otherwise(0.0))\n",
    "\n",
    "print(\"New features created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae6461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== DECISION TREE REGRESSOR TRAINING ===\")\n",
    "\n",
    "# String indexing for categorical variables\n",
    "categorical_cols = ['state', 'has_photo']\n",
    "indexers = []\n",
    "indexed_cols = []\n",
    "\n",
    "for col_name in categorical_cols:\n",
    "    if col_name in df_clean.columns:\n",
    "        indexer = StringIndexer(\n",
    "            inputCol=col_name,\n",
    "            outputCol=f\"{col_name}_idx\",\n",
    "            handleInvalid=\"keep\"\n",
    "        )\n",
    "        indexers.append(indexer)\n",
    "        indexed_cols.append(f\"{col_name}_idx\")\n",
    "\n",
    "# Final feature set\n",
    "final_features = [\n",
    "    'bedrooms', 'bathrooms', 'square_feet',\n",
    "    'price_per_sqft', 'total_rooms', 'location_score', 'room_density'\n",
    "] + indexed_cols\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=final_features,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Decision Tree Regressor\n",
    "dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"price\", maxDepth=10)\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=indexers + [assembler, dt])\n",
    "\n",
    "# Train/test split\n",
    "train_data, test_data = df_clean.randomSplit([0.8, 0.2], seed=42)\n",
    "print(f\"Training data: {train_data.count()} rows\")\n",
    "print(f\"Test data: {test_data.count()} rows\")\n",
    "\n",
    "# Train model\n",
    "dt_model = pipeline.fit(train_data)\n",
    "\n",
    "# Predictions\n",
    "predictions = dt_model.transform(test_data)\n",
    "predictions.select(\"features\", \"price\", \"prediction\").show(5, truncate=False)\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Decision Tree RMSE = {rmse:.2f}\")\n",
    "\n",
    "# Model summary\n",
    "tree_model = dt_model.stages[-1]\n",
    "print(\"Decision Tree Depth:\", tree_model.depth)\n",
    "print(\"Number of Nodes:\", tree_model.numNodes)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
